{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING LIBRARY FOR HANDING DATAFRAME AND DATA VISUALIZATION\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READING THE CSV FILE USING THE PYTHON\n",
    "crop_dataframe = pd.read_csv(\"crop dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                          CROPS DATASET CLEANING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAYING THE DATAFRAME\n",
    "crop_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE NULL VALUE\n",
    "crop_dataframe.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK THE COUNT \n",
    "crop_dataframe.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROP THE ROW STOCK WHICH IS NOT USED FOR ANALYSIS\n",
    "crop_dataframe.drop(crop_dataframe[crop_dataframe[\"Element\"] == \"Stocks\"].index, axis=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE MISSING VALUE FOR THE PRODUCTION USING FLAG DESCRIPTION\n",
    "crop_dataframe[crop_dataframe[\"Flag Description\"]==\"Missing value (data cannot exist, not applicable)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROP THE MISSING VALUE\n",
    "crop_dataframe.drop(crop_dataframe[crop_dataframe[\"Flag Description\"] == \"Missing value (data cannot exist, not applicable)\"].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK WHETHER ANY NULL VALUE IN ITEM CODE AND FILLED THE NULL VALUE IN ORIGINAL CSV FILE\n",
    "crop_dataframe[crop_dataframe['Item Code (CPC)'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFTER DROPING AND FILLING THE VALUE AGAIN CHECKING THE NULL\n",
    "crop_dataframe.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILLING NULL USING MODE\n",
    "mode_area_harvested = crop_dataframe[crop_dataframe['Element'] == 'Area harvested']['Value'].mode()[0]\n",
    "crop_dataframe.loc[(crop_dataframe['Element'] == 'Area harvested') & (crop_dataframe['Value'].isna()), 'Value'] = mode_area_harvested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILLING NULL USING MODE\n",
    "mode_area_harvested = crop_dataframe[crop_dataframe['Element'] == 'Yield']['Value'].mode()[0]\n",
    "crop_dataframe.loc[(crop_dataframe['Element'] == 'Yield') & (crop_dataframe['Value'].isna()), 'Value'] = mode_area_harvested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILLING NULL USING MODE\n",
    "mode_area_harvested = crop_dataframe[crop_dataframe['Element'] == 'Production']['Value'].mode()[0]\n",
    "crop_dataframe.loc[(crop_dataframe['Element'] == 'Production') & (crop_dataframe['Value'].isna()), 'Value'] = mode_area_harvested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILLING THE REMAINING THE NULL VALUE\n",
    "crop_dataframe[\"Value\"].fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROP THE UNWANTED COLUMNS WHICH IS NOT USED FOR ANALYSIS AND TRAING \n",
    "crop_dataframe.drop(columns=\"Note\", inplace=True)\n",
    "crop_dataframe.drop(columns=\"Year Code\", inplace=True)\n",
    "crop_dataframe.drop(columns=\"Flag\", inplace=True)\n",
    "crop_dataframe.drop(columns=\"Flag Description\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE UNIQUE VALUE IN ELEMENT FOR SEPARATE THE COLUMNS FOR PREDICTION\n",
    "crop_dataframe[\"Element\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEPARATE THE COLUMNS USING THE LOOPS\n",
    "elements = ['Area harvested', 'Yield',\n",
    "       'Producing Animals/Slaughtered', 'Laying', 'Yield/Carcass Weight',\n",
    "       'Milk Animals','Production']\n",
    "\n",
    "for element in elements:\n",
    "    Tranformed_Columns = crop_dataframe['Element'] == element\n",
    "    crop_dataframe[f'{element}_Value'] = crop_dataframe['Value'].where(Tranformed_Columns, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAYING THE SEPARATED COLUMNS\n",
    "crop_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENAME THE COLUMNS WITH UNIT \n",
    "crop_dataframe = crop_dataframe.rename(columns={\"Area harvested_Value\": \"Area_Harvested_in_Hectares\"})\n",
    "crop_dataframe = crop_dataframe.rename(columns={\"Yield_Value\": \"Yield_Value in kg/ha(or)mg/Ar\"})\n",
    "crop_dataframe = crop_dataframe.rename(columns={\"Production_Value\": \"Production in Tones\"})\n",
    "crop_dataframe = crop_dataframe.rename(columns={\"Producing Animals/Slaughtered_Value\": \"Producing Animals/Slaughtered_Value in An\"})\n",
    "crop_dataframe = crop_dataframe.rename(columns={\"Laying_Value\": \"Laying_Value in An\"})\n",
    "crop_dataframe = crop_dataframe.rename(columns={\"Yield/Carcass Weight_Value\": \"Yield/Carcass Weight_Value in g/An\"})\n",
    "crop_dataframe = crop_dataframe.rename(columns={\"Milk Animals_Value\": \"Milk Animals_Value in An\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROPING THE COLUMNS WHICH IS USED BEFORE SEPERATION\n",
    "crop_dataframe.drop(\"Element\",axis = 1,inplace = True)\n",
    "crop_dataframe.drop(\"Value\",axis = 1,inplace = True)\n",
    "crop_dataframe.drop(\"Unit\",axis = 1,inplace = True)\n",
    "crop_dataframe.drop(\"Element Code\",axis = 1,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GROUPING THE COLUMNS BY YEAR TO MAKE THE PROPER DATAFRAME FOR PREDICTION AND ANALYSIS\n",
    "grouped_crop_Dataframe = crop_dataframe.groupby(\n",
    "    ['Domain','Area', 'Item','Item Code (CPC)','Year'], as_index=False\n",
    ").agg({\n",
    "    'Area_Harvested_in_Hectares': 'sum',  \n",
    "    'Yield_Value in kg/ha(or)mg/Ar': 'sum',  \n",
    "    'Producing Animals/Slaughtered_Value in An': 'sum',  \n",
    "    'Laying_Value in An': 'sum',  \n",
    "    'Yield/Carcass Weight_Value in g/An': 'sum',  \n",
    "    'Milk Animals_Value in An': 'sum',  \n",
    "    'Production in Tones': 'sum'  \n",
    "})\n",
    "\n",
    "\n",
    "grouped_crop_Dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AFTER GROUPING CHECKING THE COUNT\n",
    "grouped_crop_Dataframe.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AFTER GROUPING CHECKING THE NULL AGAIN\n",
    "grouped_crop_Dataframe.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE DATA TYPE \n",
    "grouped_crop_Dataframe.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AFTER CHECKING DATATYPE THE ITEM CODE IS OBJECT BUT IT IS FLOAT REPLACE THE ONE WRONG OBJECT WITH FLOAT\n",
    "grouped_crop_Dataframe['Item Code (CPC)']=grouped_crop_Dataframe['Item Code (CPC)'].replace('2351f','2351')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVERTING THE ITEM CODE DATATYPE TO FLOAT\n",
    "grouped_crop_Dataframe['Item Code (CPC)']=grouped_crop_Dataframe['Item Code (CPC)'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AFTER CONVERTING AGAIN CHECKING THE DATATYPE\n",
    "grouped_crop_Dataframe.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROUND THE COLUMNS VALUE FOR GOOD TRAINING\n",
    "columns_to_round = [\n",
    "    \"Area_Harvested_in_Hectares\",\n",
    "    \"Yield_Value in kg/ha(or)mg/Ar\",\n",
    "    \"Producing Animals/Slaughtered_Value in An\",\n",
    "    \"Laying_Value in An\",\n",
    "    \"Yield/Carcass Weight_Value in g/An\",\n",
    "    \"Milk Animals_Value in An\",\n",
    "    \"Production in Tones\"\n",
    "]\n",
    "\n",
    "grouped_crop_Dataframe[columns_to_round] = grouped_crop_Dataframe[columns_to_round].round(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE TARGET PRODUCTION HAS ANY O VALUES\n",
    "grouped_crop_Dataframe[grouped_crop_Dataframe[\"Production in Tones\"]==0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROPING THE ROW HAS PRODUCTION=0\n",
    "grouped_crop_Dataframe = grouped_crop_Dataframe[grouped_crop_Dataframe[\"Production in Tones\"] != 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Area</th>\n",
       "      <th>Item</th>\n",
       "      <th>Item Code (CPC)</th>\n",
       "      <th>Year</th>\n",
       "      <th>Area_Harvested_in_Hectares</th>\n",
       "      <th>Yield_Value in kg/ha(or)mg/Ar</th>\n",
       "      <th>Producing Animals/Slaughtered_Value in An</th>\n",
       "      <th>Laying_Value in An</th>\n",
       "      <th>Yield/Carcass Weight_Value in g/An</th>\n",
       "      <th>Milk Animals_Value in An</th>\n",
       "      <th>Production in Tones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Domain, Area, Item, Item Code (CPC), Year, Area_Harvested_in_Hectares, Yield_Value in kg/ha(or)mg/Ar, Producing Animals/Slaughtered_Value in An, Laying_Value in An, Yield/Carcass Weight_Value in g/An, Milk Animals_Value in An, Production in Tones]\n",
       "Index: []"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##CHECKING THE TARGET PRODUCTION HAS ANY O VALUES AFTER REMOVING THE 0 VALUE ROWS\n",
    "grouped_crop_Dataframe[grouped_crop_Dataframe[\"Production in Tones\"]==0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE NULL AGAIN\n",
    "grouped_crop_Dataframe.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY THE CLEANED AND PREPROCESSED DATA FOR TRAINING THE MODEL\n",
    "grouped_crop_Dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECKING THE DUPLICATE AFTER CLEANING THE DATAFRAME\n",
    "grouped_crop_Dataframe.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVERTING THE CLEANED DATAFRAME TO CSV\n",
    "grouped_crop_Dataframe.to_csv(\"CLEANED_CROP_DATASET.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY THE ROW THAT HAVING THE PRODUCTION ALONE WITH THE INPUT DATA \n",
    "columns_to_zero = [\n",
    "    'Area_Harvested_in_Hectares',\n",
    "    'Yield_Value in kg/ha(or)mg/Ar',\n",
    "    'Producing Animals/Slaughtered_Value in An',\n",
    "    'Laying_Value in An',\n",
    "    'Yield/Carcass Weight_Value in g/An',\n",
    "    'Milk Animals_Value in An'\n",
    "]\n",
    "\n",
    "rows_with_zero = grouped_crop_Dataframe[grouped_crop_Dataframe[columns_to_zero].eq(0).all(axis=1)]\n",
    "rows_with_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY THE DATAFRAME AFTER REMOVING THE ALL THE INPUT HAVE 0.0\n",
    "grouped_crop_Dataframe = grouped_crop_Dataframe[~grouped_crop_Dataframe[columns_to_zero].eq(0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                             EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AGAIN IMPORTING LIBRARIES FOR EDA \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNIVARIENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE INFO FOR DATAFRAME\n",
    "grouped_crop_Dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE DESCRIPTION FOR DATAFRAME\n",
    "grouped_crop_Dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE ALL YEAR UNIQUE\n",
    "grouped_crop_Dataframe[\"Year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COLUMNS NAME\n",
    "grouped_crop_Dataframe.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BI-VARIENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET THE TOP 10 AREAS BY PRODUCTION IN TONES IN BAR CHART'\n",
    "grouped_crop_DF = grouped_crop_Dataframe.groupby('Area', as_index=False).sum()\n",
    "top_10_areas = grouped_crop_DF.nlargest(10, 'Production in Tones')\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"Area\", y=\"Production in Tones\", data=top_10_areas, palette=\"viridis\")\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.title(\"Top 10 Areas by Production in Tones\")\n",
    "plt.xlabel(\"Area\")\n",
    "plt.ylabel(\"Production in Tones\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET THE TOP 10 ITEMS BY PRODUCTION IN TONES IN BAR CHART'\n",
    "grouped_crop_DF = grouped_crop_Dataframe.groupby('Item', as_index=False).sum()\n",
    "top_10_areas = grouped_crop_DF.nlargest(10, 'Production in Tones')\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"Area\", y=\"Production in Tones\", data=top_10_areas, palette=\"viridis\")\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.title(\"Top 10 Item by Production in Tones\")\n",
    "plt.xlabel(\"Area\")\n",
    "plt.ylabel(\"Production in Tones\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MULTI-VARIENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET THE TOP 10 AREA FOR EACH YEAR\n",
    "grouped_crop_DF = grouped_crop_Dataframe.groupby(['Year', 'Area'], as_index=False).sum()\n",
    "top_10_areas_per_year = grouped_crop_DF.groupby('Year').apply(lambda x: x.nlargest(10, 'Production in Tones')).reset_index(drop=True)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"Area\", y=\"Production in Tones\", hue=\"Year\", data=top_10_areas_per_year, palette=\"viridis\")\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.title(\"Top 10 Area by Production in Tones for Each Year\")\n",
    "plt.xlabel(\"Area\")\n",
    "plt.ylabel(\"Production in Tones\")\n",
    "plt.legend(title='Year')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET THE TOP 10 ITEM FOR EACH YEAR\n",
    "grouped_crop_DF = grouped_crop_Dataframe.groupby(['Year', 'Item'], as_index=False).sum()\n",
    "top_10_areas_per_year = grouped_crop_DF.groupby('Year').apply(lambda x: x.nlargest(10, 'Production in Tones')).reset_index(drop=True)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"Item\", y=\"Production in Tones\", hue=\"Year\", data=top_10_areas_per_year, palette=\"viridis\")\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.title(\"Top 10 Item by Production in Tones for Each Year\")\n",
    "plt.xlabel(\"Items\")\n",
    "plt.ylabel(\"Production in Tones\")\n",
    "plt.legend(title='Year')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                              MODEL TRAINING AND PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING THE LIBRARIES FOR MODEL TRAINING AND SPLITING\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT PRODUCTION IN TONNES TO KILOTONNES (DIVIDE BY 1000) FOR TRAINING THE GOOD MODEL\n",
    "grouped_crop_Dataframe[\"Production in Kilotonnes\"] = grouped_crop_Dataframe[\"Production in Tones\"] / 1000\n",
    "\n",
    "# CONVERT THE COLUMN TO FLOAT (IF IT'S NOT ALREADY) AND ROUND IT TO 3 DECIMAL PLACES\n",
    "grouped_crop_Dataframe[\"Production in Kilotonnes\"] = grouped_crop_Dataframe[\"Production in Kilotonnes\"].astype(float)\n",
    "\n",
    "# ROUND THE VALUES TO 3 DECIMAL POINTS\n",
    "grouped_crop_Dataframe[\"Production in Kilotonnes\"] = grouped_crop_Dataframe[\"Production in Kilotonnes\"].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY THE DATA AFTER CONVERT THE PRODUCTION IN TONES TO KILOTONNES\n",
    "grouped_crop_Dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHOOSING THE COLUMNS FOR TRAINING AND TESTING THE MODEL X:FEATURES AND Y: TARGET\n",
    "x=grouped_crop_Dataframe[['Item Code (CPC)','Area_Harvested_in_Hectares','Yield_Value in kg/ha(or)mg/Ar','Producing Animals/Slaughtered_Value in An','Laying_Value in An','Yield/Carcass Weight_Value in g/An','Milk Animals_Value in An']]\n",
    "y=grouped_crop_Dataframe['Production in Kilotonnes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REDUCE THE SIZE OF X BUT NOT USED IN MODEL TRAINING BECAUSE IT NOT GOOD WHILE TRAINING\n",
    "X = grouped_crop_Dataframe[['Area_Harvested_in_Hectares','Yield_Value in kg/ha(or)mg/Ar',\n",
    "                            'Producing Animals/Slaughtered_Value in An','Laying_Value in An',\n",
    "                            'Yield/Carcass Weight_Value in g/An','Milk Animals_Value in An']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "X_scaled.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITING THE FEATURE AND TARGET FOR THE TRAINING MODEL\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of y_test: min=0.0, max=624402.018\n"
     ]
    }
   ],
   "source": [
    "# Check the range of y_test\n",
    "print(f\"Range of y_test: min={y_test.min()}, max={y_test.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING THE OBJECT FOR CALLING THE LINEAR REG MODDEL\n",
    "linear_model=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAING THE MODEL BY TRAING DATA\n",
    "linear_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE PREDICTION FOR THE TRAINED MODEL BY GIVING TESTING DATA\n",
    "y_predict=linear_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY THE PREDICTED OUTPUT\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE SCORE FOR THE TRAINED MODEL\n",
    "linear_model_r2 = linear_model.score(x_test, y_test)  \n",
    "print(f\"R square: {linear_model_r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE ERROR FOR THE TRAINED MODEL\n",
    "linear_model_mse = mean_squared_error(y_test, y_predict)\n",
    "print(f\"Mean Squared Error: {linear_model_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING THE DATAFRAME FOR TESTING THE MODEL WITH NEW DATA SET\n",
    "data_dict = {\n",
    "    'Item Code (CPC)':1371.0,\n",
    "    \"Area_Harvested_in_Hectares\": [29203.0],\n",
    "    \"Yield_Value in kg/ha(or)mg/Ar\": [1308.3],\n",
    "    \"Producing Animals/Slaughtered_Value in An\": [0.0],\n",
    "    \"Laying_Value in An\": [0.0],\n",
    "    \"Yield/Carcass Weight_Value in g/An\": [0.0],\n",
    "    \"Milk Animals_Value in An\": [0.0]\n",
    "}\n",
    "data_df = pd.DataFrame(data_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICT THE OUTPUT WITH NEW DATA SET\n",
    "y_predict_test = linear_model.predict(data_df)\n",
    "print(y_predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINED MODEL WITH LINEAR REG SCORE IS LOW SO WE GO FOR RIDGE REG\n",
    "from sklearn.linear_model import Ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING THE OBJECT FOR CALLING THE LINEAR RIDGE MODDEL\n",
    "ridge_model = Ridge(alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAING THE MODEL BY TRAING DATA\n",
    "ridge_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE PREDICTION FOR THE TRAINED RIDGE MODEL BY GIVING TESTING DATA\n",
    "y1_pred = ridge_model.predict(x_test)\n",
    "y1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE SCORE FOR THE TRAINED RIDGE MODEL\n",
    "ridge_model_r2= ridge_model.score(x_test, y_test)  \n",
    "print(f\"R square: {ridge_model_r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINED MODEL WITH LASSO REG SCORE IS LOW SO WE GO FOR RIDGE REG\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING THE OBJECT FOR CALLING THE LINEAR LASSO MODDEL\n",
    "lasso_model = Lasso(alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAING THE MODEL BY TRAING DATA\n",
    "lasso_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE PREDICTION FOR THE TRAINED LASSO MODEL BY GIVING TESTING DATA\n",
    "y2_pred = lasso_model.predict(x_test)\n",
    "y2_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE SCORE FOR THE TRAINED LASSO REG MODEL\n",
    "lasso_model_r2 = ridge_model.score(x_test, y_test)  \n",
    "print(f\"R2 Square: {lasso_model_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICT THE OUTPUT WITH NEW DATA SET\n",
    "y3_predict_test = lasso_model.predict(data_df)\n",
    "print(y3_predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCORE IS LOW FOR LASSO REG WE GO FOR RANDOM FOREST REGRESSOR\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING THE OBJECT FOR CALLING THE RANDOM FOREST REG MODDEL\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAING THE RANDOM FOREST REG MODEL BY TRAING DATA\n",
    "rf_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE PREDICTION FOR THE TRAINED RF MODEL BY GIVING TESTING DATA\n",
    "y3_pred = rf_model.predict(x_test)\n",
    "y3_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE SCORE FOR THE TRAINED RF REG MODEL\n",
    "rf_model_r2 = rf_model.score(x_test, y_test) \n",
    "print(f\"R Square: {rf_model_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE ERROR FOR THE TRAINED MODEL\n",
    "rf_model_mse = mean_squared_error(y_test, y_predict)\n",
    "print(f\"Mean Squared Error: {rf_model_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICT THE OUTPUT WITH NEW DATA SET\n",
    "y3_predict_test = rf_model.predict(data_df)\n",
    "print(y3_predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT JOBLIB TO SAVE THE TRAINED GOOD MODEL\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# SAVE THE GOOD TRAINED RANDOM FOREST REG MODEL\n",
    "joblib.dump(rf_model, r'c:\\Users\\arune\\OneDrive\\Desktop\\CROP PRODUCTION PREDICTION.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST REG TRAINED MODEL SCORE IS GOOD , EVENTHOUGH TRAINING THE MODEL BY XGBOOST FOR CHECKING THE SCORE\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING THE OBJECT FOR CALLING THE XG BOOST REG MODDEL\n",
    "xg_reg = xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1, max_depth=5, alpha=10, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TRAING THE XG BOOST REG MODEL BY TRAING DATA\n",
    "xg_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE PREDICTION FOR THE TRAINED XG BOOST MODEL BY GIVING TESTING DATA\n",
    "y4_pred = xg_reg.predict(x_test)\n",
    "y4_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE ERROR FOR THE TRAINED XG BOOST REG MODEL\n",
    "xgboost_model_mse = mean_squared_error(y_test, y4_pred)\n",
    "print(f\"Mean Squared Error: {xgboost_model_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE ERROR FOR THE TRAINED XG BOOST MODEL\n",
    "xgboost_model_r2 = xg_reg.score(x_test, y_test) \n",
    "print(f\"R Square: {xgboost_model_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICT THE OUTPUT WITH NEW DATA SET\n",
    "y4_predict_test = xg_reg.predict(data_df)\n",
    "print(y4_predict_test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
